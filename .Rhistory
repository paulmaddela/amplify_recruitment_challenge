remove_columns <- c("log_click_proportion","user_hist_paid","user_hist_stars","booking_value")
most_complete <- most_complete[, ! names(most_complete) %in% remove_columns]
plot_missing(most_complete)
jpeg(file="output/missing-stage3.jpeg")
plot_missing(data)
dev.off()
length(unique(most_complete$search_id))
freq(most_complete$user_country_id,order = "freq",headings = TRUE)
freq(most_complete$listing_country_id,order = "freq",headings = TRUE)
freq(most_complete)
#### Seperate data in to a set of features
id_columns_with_date <-
c(
"search_id",
"timestamp",
"site_id",
"user_country_id",
"listing_country_id",
"listing_id",
"destination_id",
)
possible_target_variables <-
c(
"search_id",
"timestamp",
"clicked",
"booked"
)
id_data <- most_complete[,id_columns_with_date]
id_data$date <- date(id_data$timestamp)
id_data$day <- day(id_data$date)
id_data$week <- week(id_data$date)
id_data$month <- month(id_data$date)
id_data <- most_complete[,id_columns_with_date]
#### Seperate data in to a set of features
id_columns_with_date <-
c(
"search_id",
"timestamp",
"site_id",
"user_country_id",
"listing_country_id",
"listing_id",
"destination_id"
)
possible_target_variables <-
c(
"search_id",
"timestamp",
"clicked",
"booked"
)
id_data <- most_complete[,id_columns_with_date]
id_data$date <- date(id_data$timestamp)
id_data$day <- day(id_data$date)
id_data$week <- week(id_data$date)
id_data$month <- month(id_data$date)
View(id_data)
52*7
53*7
plot(id_data$week)
str(id_data$week)
summary(id_data$week)
hist(id_data$week)
hist(id_data$month)
table(id_data$month)
ggplot2(id_data) + aes(x = month) + geom_count()
library(tidyverse)
library(lubridate)
library(ggplot2)
library(DataExplorer)
library(summarytools)
ggplot2(id_data) + aes(x = month) + geom_count()
ggplot(id_data) + aes(x = month) + geom_count()
ggplot(id_data) + aes(x = month, y = search_id) + geom_count()
ggplot(id_data) + aes(x = month, y = week) + geom_count()
ggplot(id_data) + aes(x = month, y = week) + geom_bar()
ggplot(id_data) + aes(x = month, y = week) + geom_bar(stat = "Count")
ggplot(id_data) + aes(x = month, y = week) + geom_bar()
ggplot(id_data) + aes(x = month, y = week) + geom_point()
library(reshape2)
test <- reshape2::recast(data = id_data,id.var = "month",measure.var = "search_id" )
test <- reshape2::dcast(id_data,month~search_id,"count")
test <- reshape2::dcast(id_data,month~search_id,count)
test <- reshape2::dcast(id_data,month~search_id,length)
View(test)
test <- reshape2::dcast(id_data,search_id~month,length)
test <- reshape2::dcast(id_data,search_id~month,mean)
test <- reshape2::dcast(id_data,search_id~month,length)
test <- unique(id_data[,c("search_id","month")])
ggplot(data = test) + geom_bar()
ggplot(data = test) + aes(x = month) + geom_bar()
ggplot(data = test) + aes(month) + geom_histogram()
ggplot(data = test) + aes(month) + geom_bar()
ggplot(data = test) + aes(month) + geom_boxplot()
ggplot(data = test) + aes(month) + geom_bar()
test <- unique(id_data[,c("search_id","week")])
test <- unique(id_data[,c("search_id","month")])
test <- unique(id_data[,c("search_id","month")])
test$month <- as.factor(as.character(test$month))
ggplot(data = test) + aes(month) + geom_bar()
ggplot(data = test) + aes(month) + geom_contour()
ggplot(data = test) + aes(month) + geom_bar()
ggplot(data = test,aes(x = month,y = search_id)) + geom_bar()
ggplot(data = test,aes(x = month)) + geom_bar()
ggplot(data = id_data,aes(x = month)) + geom_bar()
ggplot(data = id_data,aes(x = week)) + geom_bar()
ggplot(data = id_data,aes(x = week)) + geom_area()
ggplot(id_data) + aes(x = month, y = week) + geom_point()
id_data <- most_complete[,id_columns_with_date]
# Model inspired by following kernel.
# https://www.kaggle.com/aljaz91/ibm-s-attrition-tackling-class-imbalance-with-gbm#Modeling-(GBM-with-weighting,-SMOTE-and-up-&-down-sampling)
library(rsample)
library(randomForest)
library(caret)
library(e1071)
library(pROC)
library(summarytools)
library(DMwR)
preprocessed_data <- readRDS("output/data/preprocessed_data.rds")
str(preprocessed_data)
preprocessed_data$listing_id <- NULL
# There is over 42% correlation in both the variables, as seen during
# preprocessing correlation checks. Creating a composite feature.
preprocessed_data$composite_score <-
(preprocessed_data$listing_review_score + preprocessed_data$location_score1) / 2
preprocessed_data$listing_review_score <- NULL
preprocessed_data$location_score1 <- NULL
freq(preprocessed_data$clicked)
freq(preprocessed_data$booked)
# In the whole data, booked rows are only 2.89 % compared to 4.58 % of clicked.
# But, booked is for more important than clicked hence modelling for booked
preprocessed_data$clicked <- NULL
ids <- preprocessed_data[, c("search_id", "timestamp")]
preprocessed_data$search_id <- NULL
preprocessed_data$timestamp <- NULL
preprocessed_data$booked <-
as.factor(as.character(preprocessed_data$booked))
preprocessed_data$booked <- as.character(preprocessed_data$booked)
preprocessed_data$booked <-
ifelse(preprocessed_data$booked == 0, "no", "yes")
preprocessed_data$booked <- as.factor(preprocessed_data$booked)
summary(preprocessed_data$booked)
split <-
rsample::initial_split(preprocessed_data, prop = 0.8, strata = "booked")
split
train <- training(split)
test <- testing(split)
train <- train[1:10000, ]
test <- test[1:10000, ]
set.seed(1)
folds <- 4
index <- createFolds(factor(train$booked), folds, returnTrain = T)
# Basic GBM
set.seed(1)
ctrl <- trainControl(
index = index,
method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE
)
gbm_fit <- train(
booked ~ .,
data = train,
method = "gbm",
metric = "ROC",
trControl = ctrl
)
summary(gbm_fit)
gbm_fit$bestTune
gbm_preds <- predict(gbm_fit, test)
roc_gbm <- roc(as.numeric(test$booked), as.numeric(gbm_preds))
roc_gbm$auc
#saveRDS(gbm_fit,"output/models/gbm_fit.rds")
#gbm_fit <- readRDS("output/models/gbm_fit.rds")
# Weighted GBM
ctrl$seeds <- gbm_fit$control$seeds
model_weights <- ifelse(train$booked == "no",
(1 / table(train$booked)[1]) * 0.5,
(1 / table(train$booked)[2]) * 0.5)
weighted_fit <- train(
booked ~ .,
data = train,
method = "gbm",
#                     verbose = FALSE,
weights = model_weights,
metric = "ROC",
trControl = ctrl
)
weighted_preds <- predict(weighted_fit, test)
roc_weight <-
roc(as.numeric(test$booked), as.numeric(weighted_preds))
roc_weight$auc
# SMOTE
ctrl$sampling <- "smote"
smote_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
summary(smote_fit)
smote_preds <- predict(smote_fit, test)
roc_smote <- roc(as.numeric(test$booked), as.numeric(smote_preds))
roc_smote$auc
# Up
ctrl$sampling <- "up"
up_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
up_preds <- predict(up_fit, test)
roc_up <- roc(as.numeric(test$booked), as.numeric(up_preds))
roc_up$auc
# DOWN-sampling
ctrl$sampling <- "down"
down_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
down_preds <- predict(down_fit, test)
roc_down <- roc(as.numeric(test$booked), as.numeric(down_preds))
roc_down$auc
plot(
roc_gbm,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
main = "ROC curves",
col = "salmon"
)
plot(
roc_weight,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "steelblue",
add = T
)
plot(
roc_up,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "burlywood",
add = T
)
jpeg(file = "output/plots/model.jpeg")
plot(
roc_down,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "darkolivegreen",
add = T
)
dev.off()
# Model inspired by following kernel.
# https://www.kaggle.com/aljaz91/ibm-s-attrition-tackling-class-imbalance-with-gbm#Modeling-(GBM-with-weighting,-SMOTE-and-up-&-down-sampling)
library(rsample)
library(randomForest)
library(caret)
library(e1071)
library(pROC)
library(summarytools)
library(DMwR)
preprocessed_data <- readRDS("output/data/preprocessed_data.rds")
str(preprocessed_data)
preprocessed_data$listing_id <- NULL
# There is over 42% correlation in both the variables, as seen during
# preprocessing correlation checks. Creating a composite feature.
preprocessed_data$composite_score <-
(preprocessed_data$listing_review_score + preprocessed_data$location_score1) / 2
preprocessed_data$listing_review_score <- NULL
preprocessed_data$location_score1 <- NULL
freq(preprocessed_data$clicked)
freq(preprocessed_data$booked)
# In the whole data, booked rows are only 2.89 % compared to 4.58 % of clicked.
# But, booked is for more important than clicked hence modelling for booked
preprocessed_data$clicked <- NULL
ids <- preprocessed_data[, c("search_id", "timestamp")]
preprocessed_data$search_id <- NULL
preprocessed_data$timestamp <- NULL
preprocessed_data$booked <-
as.factor(as.character(preprocessed_data$booked))
preprocessed_data$booked <- as.character(preprocessed_data$booked)
preprocessed_data$booked <-
ifelse(preprocessed_data$booked == 0, "no", "yes")
preprocessed_data$booked <- as.factor(preprocessed_data$booked)
summary(preprocessed_data$booked)
split <-
rsample::initial_split(preprocessed_data, prop = 0.8, strata = "booked")
split
train <- training(split)
test <- testing(split)
train <- train[1:100000, ]
test <- test[1:10000, ]
set.seed(1)
folds <- 4
index <- createFolds(factor(train$booked), folds, returnTrain = T)
# Basic GBM
set.seed(1)
ctrl <- trainControl(
index = index,
method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE
)
gbm_fit <- train(
booked ~ .,
data = train,
method = "gbm",
metric = "ROC",
trControl = ctrl
)
summary(gbm_fit)
gbm_fit$bestTune
gbm_preds <- predict(gbm_fit, test)
roc_gbm <- roc(as.numeric(test$booked), as.numeric(gbm_preds))
roc_gbm$auc
#saveRDS(gbm_fit,"output/models/gbm_fit.rds")
#gbm_fit <- readRDS("output/models/gbm_fit.rds")
# Weighted GBM
ctrl$seeds <- gbm_fit$control$seeds
model_weights <- ifelse(train$booked == "no",
(1 / table(train$booked)[1]) * 0.5,
(1 / table(train$booked)[2]) * 0.5)
weighted_fit <- train(
booked ~ .,
data = train,
method = "gbm",
#                     verbose = FALSE,
weights = model_weights,
metric = "ROC",
trControl = ctrl
)
weighted_preds <- predict(weighted_fit, test)
roc_weight <-
roc(as.numeric(test$booked), as.numeric(weighted_preds))
roc_weight$auc
# SMOTE
ctrl$sampling <- "smote"
smote_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
summary(smote_fit)
smote_preds <- predict(smote_fit, test)
roc_smote <- roc(as.numeric(test$booked), as.numeric(smote_preds))
roc_smote$auc
# Up
ctrl$sampling <- "up"
up_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
up_preds <- predict(up_fit, test)
roc_up <- roc(as.numeric(test$booked), as.numeric(up_preds))
roc_up$auc
# DOWN-sampling
ctrl$sampling <- "down"
down_fit <- train(
booked ~ .,
data = train,
method = "gbm",
verbose = FALSE,
metric = "ROC",
trControl = ctrl
)
down_preds <- predict(down_fit, test)
roc_down <- roc(as.numeric(test$booked), as.numeric(down_preds))
roc_down$auc
plot(
roc_gbm,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
main = "ROC curves",
col = "salmon"
)
plot(
roc_weight,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "steelblue",
add = T
)
plot(
roc_up,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "burlywood",
add = T
)
plot(
roc_down,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "darkolivegreen",
add = T
)
plot(
roc_weight,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "steelblue"
)
rm(list = ls())
gc()
library(rsample)
library(randomForest)
library(caret)
library(e1071)
library(pROC)
library(summarytools)
library(DMwR)
preprocessed_data <- readRDS("output/data/preprocessed_data.rds")
str(preprocessed_data)
preprocessed_data$listing_id <- NULL
# There is over 42% correlation in both the variables, as seen during
# preprocessing correlation checks. Creating a composite feature.
preprocessed_data$composite_score <-
(preprocessed_data$listing_review_score + preprocessed_data$location_score1) / 2
preprocessed_data$listing_review_score <- NULL
preprocessed_data$location_score1 <- NULL
# In the whole data, booked rows are only 2.89 % compared to 4.58 % of clicked.
# But, booked is for more important than clicked hence modelling for booked
preprocessed_data$clicked <- NULL
ids <- preprocessed_data[, c("search_id", "timestamp")]
preprocessed_data$search_id <- NULL
preprocessed_data$timestamp <- NULL
preprocessed_data$booked <-
as.factor(as.character(preprocessed_data$booked))
preprocessed_data$booked <- as.character(preprocessed_data$booked)
preprocessed_data$booked <-
ifelse(preprocessed_data$booked == 0, "no", "yes")
preprocessed_data$booked <- as.factor(preprocessed_data$booked)
summary(preprocessed_data$booked)
split <-
rsample::initial_split(preprocessed_data, prop = 0.8, strata = "booked")
split
train <- training(split)
test <- testing(split)
set.seed(1)
folds <- 4
index <- createFolds(factor(train$booked), folds, returnTrain = T)
set.seed(1)
ctrl <- trainControl(
index = index,
method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE
)
model_weights <- ifelse(train$booked == "no",
(1 / table(train$booked)[1]) * 0.5,
(1 / table(train$booked)[2]) * 0.5)
weighted_fit <- train(
booked ~ .,
data = train,
method = "gbm",
#                     verbose = FALSE,
weights = model_weights,
metric = "ROC",
trControl = ctrl
)
weighted_preds <- predict(weighted_fit, test)
roc_weight <-
roc(as.numeric(test$booked), as.numeric(weighted_preds))
roc_weight$auc
saveRDS(weighted_fit,"output/models/weighted_fit.rds")
summary(weighted_fit)
weighted_fit$bestTune
weighted_fit$results
weighted_fit$results
table(test$booked,weighted_preds)
plot(
roc_weight,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "steelblue",
add = T
)
plot(
roc_weight,
ylim = c(0, 1),
print.thres = T,
print.thres.cex = 0.8,
col = "steelblue"
)
